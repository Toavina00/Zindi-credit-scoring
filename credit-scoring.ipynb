{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbR5ueRpBueK",
        "outputId": "a94c677c-9d15-431f-9d9e-b9042a56b6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Zindi-credit-scoring'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 23 (delta 3), reused 20 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 3.28 MiB | 11.83 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Toavina00/Zindi-credit-scoring\n",
        "!cp -r /content/Zindi-credit-scoring/dataset .\n",
        "!rm -rf /content/Zindi-credit-scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EYLOxby3BOpo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_BxtA1OwBOpp"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"dataset/Train.csv\")\n",
        "test  = pd.read_csv(\"dataset/Test.csv\")\n",
        "indicator = pd.read_csv(\"dataset/economic_indicators.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nqvziLKgBOps"
      },
      "outputs": [],
      "source": [
        "def preprocess(df, indicator):\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Discrete features and date features\n",
        "    df[['disbursement_year', 'disbursement_month', 'disbursement_day']] = df['disbursement_date'].str.split('-', expand=True).astype(np.int64)\n",
        "    df[['due_year', 'due_month', 'due_day']] = df['due_date'].str.split('-', expand=True).astype(np.int64)\n",
        "    df['New_versus_Repeat'] = df['New_versus_Repeat'].map(lambda x: 1 if x == \"New Loan\" else 0)\n",
        "\n",
        "    # Continuous features\n",
        "    df[\"Repay_Rate\"] = (df[\"Total_Amount_to_Repay\"] + 1) / (df[\"Total_Amount\"] + 1)\n",
        "\n",
        "    # Economical indicators\n",
        "    df_ind = indicator[[\"Country\", \"Indicator\", \"YR2020\", \"YR2021\", \"YR2022\", \"YR2023\"]].dropna()\n",
        "\n",
        "    ind_dict = {}\n",
        "    country = df_ind[\"Country\"].unique()\n",
        "    years = {k: int(k[2:])+1 for k in [\"YR2020\", \"YR2021\", \"YR2022\", \"YR2023\"]}\n",
        "    ind_list = [\"Inflation, consumer prices (annual %)\", \"Unemployment rate\", \"Official exchange rate (LCU per US$, period average)\"]\n",
        "\n",
        "    for country in df_ind[\"Country\"].unique():\n",
        "        ind_dict[country] = {}\n",
        "        for ind in ind_list:\n",
        "            ind_dict[country][ind] = {}\n",
        "            for k, v in years.items():\n",
        "                ind_dict[country][ind][v] = df_ind[(df_ind[\"Country\"] == country) & (df_ind[\"Indicator\"] == ind)][k].values[0]\n",
        "\n",
        "    for ind in ind_list:\n",
        "        df[ind] = df.apply(lambda row: ind_dict[row['country_id']][ind][row['disbursement_year']], axis=1)\n",
        "\n",
        "    df.rename(columns={\n",
        "        \"Inflation, consumer prices (annual %)\": \"Inflation\",\n",
        "        \"Unemployment rate\": \"Unemployment\",\n",
        "        \"Official exchange rate (LCU per US$, period average)\": \"Exchange_Rate\",\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Drop columns\n",
        "    df = df.drop(columns=[\n",
        "        'disbursement_date', 'due_date', \"customer_id\",\n",
        "        \"country_id\", \"tbl_loan_id\", \"lender_id\",\n",
        "        \"loan_type\", \"Total_Amount_to_Repay\",\n",
        "        \"Lender_portion_to_be_repaid\", \"disbursement_year\",\n",
        "        \"due_year\", \"Inflation\", \"due_day\", \"due_month\"\n",
        "    ])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df, indicator):\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Discrete features and date features\n",
        "    df[['disbursement_year', 'disbursement_month', 'disbursement_day']] = df['disbursement_date'].str.split('-', expand=True).astype(np.int64)\n",
        "    df[['due_year', 'due_month', 'due_day']] = df['due_date'].str.split('-', expand=True).astype(np.int64)\n",
        "    df['New_versus_Repeat'] = df['New_versus_Repeat'].map(lambda x: 1 if x == \"New Loan\" else 0)\n",
        "    df['loan_type'] = df['loan_type'].map(lambda x: 1 if x == \"type_1\" else 0)\n",
        "\n",
        "    # Continuous features\n",
        "    df[\"Repay_Rate\"] = (df[\"Total_Amount_to_Repay\"] + 1) / (df[\"Total_Amount\"] + 1)\n",
        "    df[\"Lender_Repay_Rate\"] = (df[\"Lender_portion_to_be_repaid\"] + 1) / (df[\"Amount_Funded_By_Lender\"] + 1)\n",
        "\n",
        "    # Economical indicators\n",
        "    df_ind = indicator[[\"Country\", \"Indicator\", \"YR2020\", \"YR2021\", \"YR2022\", \"YR2023\"]].dropna()\n",
        "\n",
        "    ind_dict = {}\n",
        "    country = df_ind[\"Country\"].unique()\n",
        "    years = {k: int(k[2:])+1 for k in [\"YR2020\", \"YR2021\", \"YR2022\", \"YR2023\"]}\n",
        "    ind_list = [\"Inflation, consumer prices (annual %)\", \"Unemployment rate\", \"Official exchange rate (LCU per US$, period average)\"]\n",
        "\n",
        "    for country in df_ind[\"Country\"].unique():\n",
        "        ind_dict[country] = {}\n",
        "        for ind in ind_list:\n",
        "            ind_dict[country][ind] = {}\n",
        "            for k, v in years.items():\n",
        "                ind_dict[country][ind][v] = df_ind[(df_ind[\"Country\"] == country) & (df_ind[\"Indicator\"] == ind)][k].values[0]\n",
        "\n",
        "    for ind in ind_list:\n",
        "        df[ind] = df.apply(lambda row: ind_dict[row['country_id']][ind][row['disbursement_year']], axis=1)\n",
        "\n",
        "    df.rename(columns={\n",
        "        \"Inflation, consumer prices (annual %)\": \"Inflation\",\n",
        "        \"Unemployment rate\": \"Unemployment\",\n",
        "        \"Official exchange rate (LCU per US$, period average)\": \"Exchange_Rate\",\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Drop columns\n",
        "    df = df.drop(columns=[\n",
        "        'disbursement_date', 'due_date', \"customer_id\",\n",
        "        \"country_id\", \"tbl_loan_id\", \"lender_id\",\n",
        "    ])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYdJ7gPKBOps"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IS1rjszlBOps"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, TargetEncoder, FunctionTransformer\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn import set_config\n",
        "\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from lightgbm import LGBMClassifier, plot_importance as lgb_plot_importance\n",
        "from xgboost import XGBClassifier, plot_importance as xgb_plot_importance\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "set_config(transform_output=\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl-0vOhRBOps",
        "outputId": "3dc3a32c-70eb-441e-9d0f-9ae773c60133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 68654 entries, 0 to 68653\n",
            "Data columns (total 21 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   ID                           68654 non-null  object \n",
            " 1   loan_type                    68654 non-null  int64  \n",
            " 2   Total_Amount                 68654 non-null  float64\n",
            " 3   Total_Amount_to_Repay        68654 non-null  float64\n",
            " 4   duration                     68654 non-null  int64  \n",
            " 5   New_versus_Repeat            68654 non-null  int64  \n",
            " 6   Amount_Funded_By_Lender      68654 non-null  float64\n",
            " 7   Lender_portion_Funded        68654 non-null  float64\n",
            " 8   Lender_portion_to_be_repaid  68654 non-null  float64\n",
            " 9   target                       68654 non-null  int64  \n",
            " 10  disbursement_year            68654 non-null  int64  \n",
            " 11  disbursement_month           68654 non-null  int64  \n",
            " 12  disbursement_day             68654 non-null  int64  \n",
            " 13  due_year                     68654 non-null  int64  \n",
            " 14  due_month                    68654 non-null  int64  \n",
            " 15  due_day                      68654 non-null  int64  \n",
            " 16  Repay_Rate                   68654 non-null  float64\n",
            " 17  Lender_Repay_Rate            68654 non-null  float64\n",
            " 18  Inflation                    68654 non-null  float64\n",
            " 19  Unemployment                 68654 non-null  float64\n",
            " 20  Exchange_Rate                68654 non-null  float64\n",
            "dtypes: float64(10), int64(10), object(1)\n",
            "memory usage: 11.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "df_train = preprocess(train, indicator)\n",
        "\n",
        "X, y = df_train.drop(columns='target'), df_train['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(df_train.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxmpvf8FBOps"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWAq2bFmBOpt",
        "outputId": "24054297-2d3c-44d3-ab70-9ea3da9ce3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train f1-score: 0.6157476911321593\n",
            "Validation f1-score: 0.6109205494707757\n",
            "\n",
            "Test report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     13479\n",
            "           1       0.73      0.54      0.62       252\n",
            "\n",
            "    accuracy                           0.99     13731\n",
            "   macro avg       0.86      0.77      0.81     13731\n",
            "weighted avg       0.99      0.99      0.99     13731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (\n",
        "            make_pipeline(\n",
        "                SimpleImputer(strategy='mean'),\n",
        "                StandardScaler(),\n",
        "            ), make_column_selector(dtype_include=np.float64)),\n",
        "        (\n",
        "            make_pipeline(\n",
        "                SimpleImputer(strategy='most_frequent'),\n",
        "            ), make_column_selector(dtype_include=np.int64)\n",
        "        ),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    LogisticRegression(),\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring='f1', return_train_score=True)\n",
        "\n",
        "print(f\"Train f1-score: {cv_results['train_score'].mean()}\")\n",
        "print(f\"Validation f1-score: {cv_results['test_score'].mean()}\")\n",
        "\n",
        "print(\"\\nTest report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rusXNuoBOpt"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train f1-score: 0.8784681903035885\n",
            "Validation f1-score: 0.8249531754190537\n",
            "\n",
            "Test report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     13479\n",
            "           1       0.70      0.94      0.81       252\n",
            "\n",
            "    accuracy                           0.99     13731\n",
            "   macro avg       0.85      0.97      0.90     13731\n",
            "weighted avg       0.99      0.99      0.99     13731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "continuous_columns = X.select_dtypes(include=np.float64).columns\n",
        "discrete_columns = X.select_dtypes(include=np.int64).columns\n",
        "\n",
        "continuous_columns = continuous_columns.drop([])\n",
        "discrete_columns = discrete_columns.drop([])\n",
        "\n",
        "model = make_pipeline(\n",
        "    RandomOverSampler(sampling_strategy=0.3, random_state=42),\n",
        "    make_column_transformer(\n",
        "        (SimpleImputer(strategy=\"mean\"), continuous_columns),\n",
        "        (SimpleImputer(strategy='most_frequent'), discrete_columns),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    LGBMClassifier(random_state=42, n_estimators=100, max_depth=5)\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring='f1', return_train_score=True)\n",
        "\n",
        "print(f\"Train f1-score: {cv_results['train_score'].mean()}\")\n",
        "print(f\"Validation f1-score: {cv_results['test_score'].mean()}\")\n",
        "\n",
        "print(\"\\nTest report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... | max_depth | n_esti... |  thresh   |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[39m1        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4371   \u001b[39m | \u001b[39m0.9556   \u001b[39m | \u001b[39m0.1491   \u001b[39m | \u001b[39m7.191    \u001b[39m | \u001b[39m120.2    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[35m2        \u001b[39m | \u001b[35m0.7805   \u001b[39m | \u001b[35m0.1523   \u001b[39m | \u001b[35m0.8796   \u001b[39m | \u001b[35m0.1242   \u001b[39m | \u001b[35m7.957    \u001b[39m | \u001b[35m59.26    \u001b[39m | \u001b[35m0.5      \u001b[39m |\n",
            "| \u001b[39m3        \u001b[39m | \u001b[39m0.6964   \u001b[39m | \u001b[39m0.8492   \u001b[39m | \u001b[39m0.2911   \u001b[39m | \u001b[39m0.04455  \u001b[39m | \u001b[39m4.284    \u001b[39m | \u001b[39m186.9    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m4        \u001b[39m | \u001b[39m0.7368   \u001b[39m | \u001b[39m0.4888   \u001b[39m | \u001b[39m0.3621   \u001b[39m | \u001b[39m0.1263   \u001b[39m | \u001b[39m3.976    \u001b[39m | \u001b[39m181.5    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m5        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.5105   \u001b[39m | \u001b[39m0.8067   \u001b[39m | \u001b[39m0.04794  \u001b[39m | \u001b[39m6.6      \u001b[39m | \u001b[39m316.6    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m6        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.6468   \u001b[39m | \u001b[39m0.2535   \u001b[39m | \u001b[39m0.02236  \u001b[39m | \u001b[39m9.642    \u001b[39m | \u001b[39m484.5    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m7        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.3742   \u001b[39m | \u001b[39m0.1879   \u001b[39m | \u001b[39m0.14     \u001b[39m | \u001b[39m6.081    \u001b[39m | \u001b[39m104.9    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m8        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.1309   \u001b[39m | \u001b[39m0.9184   \u001b[39m | \u001b[39m0.05917  \u001b[39m | \u001b[39m7.638    \u001b[39m | \u001b[39m190.3    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m9        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.592    \u001b[39m | \u001b[39m0.2664   \u001b[39m | \u001b[39m0.1942   \u001b[39m | \u001b[39m8.426    \u001b[39m | \u001b[39m472.8    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m10       \u001b[39m | \u001b[39m0.6582   \u001b[39m | \u001b[39m0.6381   \u001b[39m | \u001b[39m0.9297   \u001b[39m | \u001b[39m0.02681  \u001b[39m | \u001b[39m4.372    \u001b[39m | \u001b[39m70.35    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m11       \u001b[39m | \u001b[39m0.7639   \u001b[39m | \u001b[39m0.2355   \u001b[39m | \u001b[39m0.9394   \u001b[39m | \u001b[39m0.08278  \u001b[39m | \u001b[39m8.107    \u001b[39m | \u001b[39m59.15    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m12       \u001b[39m | \u001b[39m0.6618   \u001b[39m | \u001b[39m0.8693   \u001b[39m | \u001b[39m0.7764   \u001b[39m | \u001b[39m0.1917   \u001b[39m | \u001b[39m3.092    \u001b[39m | \u001b[39m62.84    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m13       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.407    \u001b[39m | \u001b[39m0.1192   \u001b[39m | \u001b[39m0.129    \u001b[39m | \u001b[39m9.795    \u001b[39m | \u001b[39m64.74    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m14       \u001b[39m | \u001b[39m0.6807   \u001b[39m | \u001b[39m0.8228   \u001b[39m | \u001b[39m0.8055   \u001b[39m | \u001b[39m0.08554  \u001b[39m | \u001b[39m4.57     \u001b[39m | \u001b[39m58.25    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m15       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.759    \u001b[39m | \u001b[39m0.5046   \u001b[39m | \u001b[39m0.1908   \u001b[39m | \u001b[39m8.004    \u001b[39m | \u001b[39m182.8    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m16       \u001b[39m | \u001b[39m0.6579   \u001b[39m | \u001b[39m0.6802   \u001b[39m | \u001b[39m0.8154   \u001b[39m | \u001b[39m0.06939  \u001b[39m | \u001b[39m3.169    \u001b[39m | \u001b[39m183.9    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m17       \u001b[39m | \u001b[39m0.7346   \u001b[39m | \u001b[39m0.148    \u001b[39m | \u001b[39m0.7903   \u001b[39m | \u001b[39m0.1331   \u001b[39m | \u001b[39m3.166    \u001b[39m | \u001b[39m177.6    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m18       \u001b[39m | \u001b[39m0.6684   \u001b[39m | \u001b[39m0.7466   \u001b[39m | \u001b[39m0.1295   \u001b[39m | \u001b[39m0.1605   \u001b[39m | \u001b[39m3.201    \u001b[39m | \u001b[39m74.81    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m19       \u001b[39m | \u001b[39m0.7485   \u001b[39m | \u001b[39m0.8066   \u001b[39m | \u001b[39m0.8104   \u001b[39m | \u001b[39m0.05158  \u001b[39m | \u001b[39m8.059    \u001b[39m | \u001b[39m75.04    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m20       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.7782   \u001b[39m | \u001b[39m0.9712   \u001b[39m | \u001b[39m0.1839   \u001b[39m | \u001b[39m6.613    \u001b[39m | \u001b[39m79.6     \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m21       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.3948   \u001b[39m | \u001b[39m0.8181   \u001b[39m | \u001b[39m0.1565   \u001b[39m | \u001b[39m8.288    \u001b[39m | \u001b[39m71.92    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m22       \u001b[39m | \u001b[39m0.6787   \u001b[39m | \u001b[39m0.9556   \u001b[39m | \u001b[39m0.3099   \u001b[39m | \u001b[39m0.02995  \u001b[39m | \u001b[39m5.811    \u001b[39m | \u001b[39m60.85    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m23       \u001b[39m | \u001b[39m0.7596   \u001b[39m | \u001b[39m0.6784   \u001b[39m | \u001b[39m0.7988   \u001b[39m | \u001b[39m0.1155   \u001b[39m | \u001b[39m6.86     \u001b[39m | \u001b[39m56.13    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m24       \u001b[39m | \u001b[39m0.6572   \u001b[39m | \u001b[39m0.813    \u001b[39m | \u001b[39m0.6127   \u001b[39m | \u001b[39m0.03871  \u001b[39m | \u001b[39m4.064    \u001b[39m | \u001b[39m53.96    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m25       \u001b[39m | \u001b[39m0.7425   \u001b[39m | \u001b[39m0.9961   \u001b[39m | \u001b[39m0.8518   \u001b[39m | \u001b[39m0.07157  \u001b[39m | \u001b[39m8.346    \u001b[39m | \u001b[39m52.26    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m26       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.8856   \u001b[39m | \u001b[39m0.1306   \u001b[39m | \u001b[39m0.1626   \u001b[39m | \u001b[39m9.843    \u001b[39m | \u001b[39m55.01    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m27       \u001b[39m | \u001b[39m0.754    \u001b[39m | \u001b[39m0.4714   \u001b[39m | \u001b[39m0.3346   \u001b[39m | \u001b[39m0.1574   \u001b[39m | \u001b[39m5.966    \u001b[39m | \u001b[39m51.44    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[35m28       \u001b[39m | \u001b[35m0.7983   \u001b[39m | \u001b[35m0.7773   \u001b[39m | \u001b[35m0.9797   \u001b[39m | \u001b[35m0.1576   \u001b[39m | \u001b[35m7.961    \u001b[39m | \u001b[35m50.15    \u001b[39m | \u001b[35m0.5      \u001b[39m |\n",
            "| \u001b[39m29       \u001b[39m | \u001b[39m0.6368   \u001b[39m | \u001b[39m0.1927   \u001b[39m | \u001b[39m0.84     \u001b[39m | \u001b[39m0.09253  \u001b[39m | \u001b[39m3.055    \u001b[39m | \u001b[39m66.74    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m30       \u001b[39m | \u001b[39m0.7682   \u001b[39m | \u001b[39m0.1664   \u001b[39m | \u001b[39m0.5769   \u001b[39m | \u001b[39m0.1002   \u001b[39m | \u001b[39m4.526    \u001b[39m | \u001b[39m174.0    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m31       \u001b[39m | \u001b[39m0.702    \u001b[39m | \u001b[39m0.8108   \u001b[39m | \u001b[39m0.3686   \u001b[39m | \u001b[39m0.01433  \u001b[39m | \u001b[39m6.481    \u001b[39m | \u001b[39m176.2    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m32       \u001b[39m | \u001b[39m0.7268   \u001b[39m | \u001b[39m0.3035   \u001b[39m | \u001b[39m0.6113   \u001b[39m | \u001b[39m0.01919  \u001b[39m | \u001b[39m7.753    \u001b[39m | \u001b[39m172.3    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m33       \u001b[39m | \u001b[39m0.7456   \u001b[39m | \u001b[39m0.854    \u001b[39m | \u001b[39m0.4515   \u001b[39m | \u001b[39m0.08122  \u001b[39m | \u001b[39m4.561    \u001b[39m | \u001b[39m170.2    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m34       \u001b[39m | \u001b[39m0.7374   \u001b[39m | \u001b[39m0.2741   \u001b[39m | \u001b[39m0.9724   \u001b[39m | \u001b[39m0.02439  \u001b[39m | \u001b[39m7.772    \u001b[39m | \u001b[39m168.1    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m35       \u001b[39m | \u001b[39m0.6833   \u001b[39m | \u001b[39m0.6074   \u001b[39m | \u001b[39m0.7367   \u001b[39m | \u001b[39m0.03419  \u001b[39m | \u001b[39m4.192    \u001b[39m | \u001b[39m165.9    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m36       \u001b[39m | \u001b[39m0.7481   \u001b[39m | \u001b[39m0.1645   \u001b[39m | \u001b[39m0.5727   \u001b[39m | \u001b[39m0.02507  \u001b[39m | \u001b[39m8.68     \u001b[39m | \u001b[39m163.7    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m37       \u001b[39m | \u001b[39m0.7034   \u001b[39m | \u001b[39m0.363    \u001b[39m | \u001b[39m0.89     \u001b[39m | \u001b[39m0.02409  \u001b[39m | \u001b[39m5.617    \u001b[39m | \u001b[39m161.3    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m38       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.8813   \u001b[39m | \u001b[39m0.9289   \u001b[39m | \u001b[39m0.1607   \u001b[39m | \u001b[39m9.866    \u001b[39m | \u001b[39m159.2    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m39       \u001b[39m | \u001b[39m0.6311   \u001b[39m | \u001b[39m0.3414   \u001b[39m | \u001b[39m0.4794   \u001b[39m | \u001b[39m0.01841  \u001b[39m | \u001b[39m3.103    \u001b[39m | \u001b[39m158.3    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "| \u001b[39m40       \u001b[39m | \u001b[39m0.6396   \u001b[39m | \u001b[39m0.3578   \u001b[39m | \u001b[39m0.868    \u001b[39m | \u001b[39m0.04487  \u001b[39m | \u001b[39m3.04     \u001b[39m | \u001b[39m152.2    \u001b[39m | \u001b[39m0.5      \u001b[39m |\n",
            "=================================================================================================\n",
            "Train f1-score: 0.9376024956869745\n",
            "Validation f1-score: 0.8607689281069838\n",
            "\n",
            "Test report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     13479\n",
            "           1       0.86      0.85      0.85       252\n",
            "\n",
            "    accuracy                           0.99     13731\n",
            "   macro avg       0.93      0.92      0.93     13731\n",
            "weighted avg       0.99      0.99      0.99     13731\n",
            "\n"
          ]
        }
      ],
      "source": [
        "continuous_columns = X.select_dtypes(include=np.float64).columns\n",
        "discrete_columns = X.select_dtypes(include=np.int64).columns\n",
        "\n",
        "continuous_columns = continuous_columns.drop([])\n",
        "discrete_columns = discrete_columns.drop([])\n",
        "\n",
        "\n",
        "def evaluate(max_depth, learning_rate, lambda_l1, lambda_l2, n_estimators, thresh):\n",
        "    params = {\n",
        "        'max_depth': int(max_depth),\n",
        "        'learning_rate': learning_rate,\n",
        "        'n_estimators': int(n_estimators),\n",
        "        'lambda_l1': lambda_l1,\n",
        "        'lambda_l2': lambda_l2,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        \"verbose\": -1,\n",
        "    }\n",
        "\n",
        "    model = make_pipeline(\n",
        "        RandomOverSampler(random_state=42),\n",
        "        make_column_transformer(\n",
        "            (SimpleImputer(strategy=\"mean\"), continuous_columns),\n",
        "            (SimpleImputer(strategy='most_frequent'), discrete_columns),\n",
        "            remainder='drop'\n",
        "        ),\n",
        "        LGBMClassifier(**params)\n",
        "    )\n",
        "    model.predict = lambda X: (model.predict_proba(X) > thresh).argmax(axis=1)\n",
        "    \n",
        "    cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring='f1', return_train_score=True)\n",
        "    \n",
        "    val_score = cv_results['test_score'].mean()\n",
        "    train_score = cv_results['train_score'].mean()\n",
        "\n",
        "    return val_score if abs(val_score - train_score) < 0.05 else 0.0\n",
        "\n",
        "param_space = {\n",
        "    'max_depth': (3, 10),\n",
        "    'learning_rate': (0.01, 0.2),\n",
        "    'n_estimators': (50, 500),\n",
        "    'thresh': (0.5, 0.5),\n",
        "    'lambda_l1': (0.1, 1.0),\n",
        "    'lambda_l2': (0.1, 1.0),\n",
        "}\n",
        "\n",
        "optimizer = BayesianOptimization(f=evaluate, pbounds=param_space, random_state=42)\n",
        "optimizer.maximize(init_points=10, n_iter=30)\n",
        "\n",
        "best_params = optimizer.max['params']\n",
        "\n",
        "model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (SimpleImputer(strategy=\"mean\"), continuous_columns),\n",
        "        (SimpleImputer(strategy='most_frequent'), discrete_columns),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    LGBMClassifier(\n",
        "        max_depth=int(best_params['max_depth']),\n",
        "        learning_rate=best_params['learning_rate'],\n",
        "        n_estimators=int(best_params['n_estimators']),\n",
        "        lambda_l1=best_params['lambda_l1'],\n",
        "        lambda_l2=best_params['lambda_l2'],\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "model.predict = lambda X: (model.predict_proba(X) > best_params[\"thresh\"]).argmax(axis=1)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring='f1', return_train_score=True)\n",
        "\n",
        "print(f\"Train f1-score: {cv_results['train_score'].mean()}\")\n",
        "print(f\"Validation f1-score: {cv_results['test_score'].mean()}\")\n",
        "\n",
        "print(\"\\nTest report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgUju0PXBOpt"
      },
      "source": [
        "### Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Jm739oBOpt",
        "outputId": "70cd34c8-feea-4767-e90a-aa19e4f8b704"
      },
      "outputs": [],
      "source": [
        "# Make submission\n",
        "\n",
        "df_test = preprocess(test, indicator)\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(df_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test[\"ID\"],\n",
        "    \"target\": y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX5gOV6WBOpt"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
